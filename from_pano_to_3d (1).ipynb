{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from pano import draw_boundary\n",
    "from pano_lsd_align import panoEdgeDetection, rotatePanorama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = 'assert/demo.png'\n",
    "output_dir = 'assert/output_preprocess/'\n",
    "q_error = 0.7\n",
    "refine_iter = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check input arguments validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(path_to_image))\n",
    "if len(paths) == 0:\n",
    "    print('no images found')\n",
    "\n",
    "# Check input arguments validation\n",
    "for path in paths:\n",
    "    assert os.path.isfile(path), '%s not found' % path\n",
    "assert os.path.isdir(output_dir), '%s is not a directory' % args.output_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_path in paths:\n",
    "    print('Processing', i_path, flush=True)\n",
    "\n",
    "    # Load and cat input images\n",
    "    img_ori = np.array(Image.open(i_path).resize((1024, 512), Image.BICUBIC))[..., :3]\n",
    "\n",
    "    # VP detection and line segment extraction\n",
    "    _, vp, _, _, panoEdge, _, _ = panoEdgeDetection(img_ori,\n",
    "                                                    qError=q_error,\n",
    "                                                    refineIter=refine_iter)\n",
    "    panoEdge = (panoEdge > 0)\n",
    "    \n",
    "    # Align images with VP\n",
    "    i_img = rotatePanorama(img_ori / 255.0, vp[2::-1])\n",
    "    l_img = rotatePanorama(panoEdge.astype(np.float32), vp[2::-1])\n",
    "\n",
    "    # Dump results\n",
    "    basename = os.path.splitext(os.path.basename(i_path))[0]\n",
    "    path_VP = os.path.join(output_dir, '%s_VP.txt' % basename)\n",
    "    path_i_img = os.path.join(output_dir, '%s_aligned_rgb.png' % basename)\n",
    "    path_l_img = os.path.join(output_dir, '%s_aligned_line.png' % basename)\n",
    "\n",
    "    with open(path_VP, 'w') as f:\n",
    "        for i in range(3):\n",
    "            f.write('%.6f %.6f %.6f\\n' % (vp[i, 0], vp[i, 1], vp[i, 2]))\n",
    "    Image.fromarray((i_img * 255).astype(np.uint8)).save(path_i_img)\n",
    "    Image.fromarray((l_img * 255).astype(np.uint8)).save(path_l_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.add_subplot(311)\n",
    "plt.imshow(img_ori)\n",
    "fig.add_subplot(312)\n",
    "plt.imshow(i_img)\n",
    "fig.add_subplot(313)\n",
    "plt.imshow(l_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import Encoder, Decoder\n",
    "from utils_eval import augment, augment_undo\n",
    "from pano import get_ini_cor, draw_boundary_from_cor_id\n",
    "from pano_opt import optimize_cor_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model related arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = 'ckpt/epoch_30'\n",
    "device = 'cuda:0'\n",
    "img_glob = 'assert/output_preprocess/demo_aligned_rgb.png'\n",
    "line_glob = 'assert/output_preprocess/demo_aligned_line.png'\n",
    "output_dir = 'assert/output'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data augmented arguments (to improve output quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = False\n",
    "rotate = []\n",
    "d1 = 21\n",
    "d2 = 2\n",
    "post_optimization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check input arguments validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in glob.glob(img_glob):\n",
    "    assert os.path.isfile(path), '%s not found' % path\n",
    "for path in glob.glob(line_glob):\n",
    "    assert os.path.isfile(path), '%s not found' % path\n",
    "assert os.path.isdir(output_dir), '%s is not a directory' % output_dir\n",
    "for rotate in rotate:\n",
    "    assert 0 <= rotate and rotate <= 1, 'elements in --rotate should in [0, 1]'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "edg_decoder = Decoder(skip_num=2, out_planes=3).to(device)\n",
    "cor_decoder = Decoder(skip_num=3, out_planes=1).to(device)\n",
    "encoder.load_state_dict(torch.load('%s_encoder.pth' % path_prefix))\n",
    "edg_decoder.load_state_dict(torch.load('%s_edg_decoder.pth' % path_prefix))\n",
    "cor_decoder.load_state_dict(torch.load('%s_cor_decoder.pth' % path_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load path to visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = sorted(glob.glob(img_glob))\n",
    "line_paths = sorted(glob.glob(line_glob))\n",
    "assert len(img_paths) == len(line_paths), '# of input mismatch for each channels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_path, l_path in zip(img_paths, line_paths):\n",
    "    print('img  path:', i_path)\n",
    "    print('line path:', l_path)\n",
    "\n",
    "    # Load and cat input images\n",
    "    i_img = np.array(Image.open(i_path), np.float32) / 255\n",
    "    l_img = np.array(Image.open(l_path), np.float32) / 255\n",
    "    x_img = np.concatenate([\n",
    "        i_img.transpose([2, 0, 1]),\n",
    "        l_img.transpose([2, 0, 1])], axis=0)\n",
    "\n",
    "    # Augment data\n",
    "    x_imgs_augmented, aug_type = augment(x_img, flip, rotate)\n",
    "\n",
    "    # Feedforward and extract output images\n",
    "    with torch.no_grad():\n",
    "        x = torch.FloatTensor(x_imgs_augmented).to(device)\n",
    "        en_list = encoder(x)\n",
    "        edg_de_list = edg_decoder(en_list[::-1])\n",
    "        cor_de_list = cor_decoder(en_list[-1:] + edg_de_list[:-1])\n",
    "\n",
    "        edg_tensor = torch.sigmoid(edg_de_list[-1])\n",
    "        cor_tensor = torch.sigmoid(cor_de_list[-1])\n",
    "\n",
    "        # Recover the effect from augmentation\n",
    "        edg_img = augment_undo(edg_tensor.cpu().numpy(), aug_type)\n",
    "        cor_img = augment_undo(cor_tensor.cpu().numpy(), aug_type)\n",
    "\n",
    "    # Merge all results from augmentation\n",
    "    edgmap = edg_img.transpose([0, 2, 3, 1]).mean(0).copy()\n",
    "    cormap = cor_img.transpose([0, 2, 3, 1]).mean(0)[..., 0].copy()\n",
    "\n",
    "    # Post processing to extract layout\n",
    "    cor_id = get_ini_cor(cormap, d1, d2)\n",
    "    if post_optimization:\n",
    "        cor_id = optimize_cor_id(cor_id, edgmap, cormap,\n",
    "                                 num_iters=100, verbose=False)\n",
    "\n",
    "    # Draw extracted layout on source image\n",
    "    bon_img = draw_boundary_from_cor_id(cor_id.copy(), i_img * 255)\n",
    "\n",
    "    # Composite all result in one image\n",
    "    all_in_one = 0.3 * edgmap + 0.3 * cormap[..., None] + 0.4 * i_img\n",
    "    all_in_one = draw_boundary_from_cor_id(cor_id.copy(), all_in_one * 255)\n",
    "\n",
    "    # Dump results\n",
    "    basename = os.path.splitext(os.path.basename(i_path))[0]\n",
    "    path_edg = os.path.join(output_dir, '%s_edg.png' % basename)\n",
    "    path_cor = os.path.join(output_dir, '%s_cor.png' % basename)\n",
    "    path_bon = os.path.join(output_dir, '%s_bon.png' % basename)\n",
    "    path_all_in_one = os.path.join(output_dir, '%s_all.png' % basename)\n",
    "    path_cor_id = os.path.join(output_dir, '%s_cor_id.txt' % basename)\n",
    "\n",
    "    Image.fromarray((edgmap * 255).astype(np.uint8)).save(path_edg)\n",
    "    Image.fromarray((cormap * 255).astype(np.uint8)).save(path_cor)\n",
    "    Image.fromarray(bon_img).save(path_bon)\n",
    "    Image.fromarray(all_in_one).save(path_all_in_one)\n",
    "    with open(path_cor_id, 'w') as f:\n",
    "        for x, y in cor_id:\n",
    "            f.write('%.6f %.6f\\n' % (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.add_subplot(411)\n",
    "plt.imshow(edgmap)\n",
    "fig.add_subplot(412)\n",
    "plt.imshow(cormap)\n",
    "fig.add_subplot(413)\n",
    "plt.imshow(bon_img)\n",
    "fig.add_subplot(414)\n",
    "plt.imshow(all_in_one)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "import open3d\n",
    "from PIL import Image\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "import functools\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from utils_eval import np_coor2xy, np_coory2v\n",
    "from open3d import JVisualizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_2_coorxy(xs, ys, zs, H, W):\n",
    "    us = np.arctan2(xs, -ys)\n",
    "    vs = -np.arctan(zs / np.sqrt(xs**2 + ys**2))\n",
    "    coorx = (us / (2 * np.pi) + 0.5) * W\n",
    "    coory = (vs / np.pi + 0.5) * H\n",
    "    return coorx, coory\n",
    "\n",
    "\n",
    "def pt_in_poly(poly, pt):\n",
    "    return poly.contains(Point(pt))\n",
    "\n",
    "\n",
    "def warp_walls(xy, floor_z, ceil_z, H, W, ppm, alpha):\n",
    "    all_rgba = []\n",
    "    all_xyz = []\n",
    "    for i in range(len(xy)):\n",
    "        next_i = (i + 1) % len(xy)\n",
    "        xy_a = xy[i]\n",
    "        xy_b = xy[next_i]\n",
    "        xy_w = np.sqrt(((xy_a - xy_b)**2).sum())\n",
    "        t_h = int(round((ceil_z - floor_z) * ppm))\n",
    "        t_w = int(round(xy_w * ppm))\n",
    "        xs = np.linspace(xy_a[0], xy_b[0], t_w)[None].repeat(t_h, 0)\n",
    "        ys = np.linspace(xy_a[1], xy_b[1], t_w)[None].repeat(t_h, 0)\n",
    "        zs = np.linspace(floor_z, ceil_z, t_h)[:, None].repeat(t_w, 1)\n",
    "        coorx, coory = xyz_2_coorxy(xs, ys, zs, H, W)\n",
    "\n",
    "        plane_texture = np.stack([\n",
    "            map_coordinates(equirect_texture[..., 0], [coory, coorx], order=1, mode='wrap'),\n",
    "            map_coordinates(equirect_texture[..., 1], [coory, coorx], order=1, mode='wrap'),\n",
    "            map_coordinates(equirect_texture[..., 2], [coory, coorx], order=1, mode='wrap'),\n",
    "            np.zeros([t_h, t_w]) + alpha,\n",
    "        ], -1)\n",
    "        plane_xyz = np.stack([xs, ys, zs], axis=-1)\n",
    "\n",
    "        all_rgba.extend(plane_texture.reshape(-1, 4))\n",
    "        all_xyz.extend(plane_xyz.reshape(-1, 3))\n",
    "\n",
    "    return all_rgba, all_xyz\n",
    "\n",
    "\n",
    "def warp_floor_ceiling(xy, z_floor, z_ceiling, H, W, ppm, alpha, n_thread):\n",
    "    min_x = xy[:, 0].min()\n",
    "    max_x = xy[:, 0].max()\n",
    "    min_y = xy[:, 1].min()\n",
    "    max_y = xy[:, 1].max()\n",
    "    t_h = int(round((max_y - min_y) * ppm))\n",
    "    t_w = int(round((max_x - min_x) * ppm))\n",
    "    xs = np.linspace(min_x, max_x, t_w)[None].repeat(t_h, 0)\n",
    "    ys = np.linspace(min_y, max_y, t_h)[:, None].repeat(t_w, 1)\n",
    "    zs_floor = np.zeros_like(xs) + z_floor\n",
    "    zs_ceil = np.zeros_like(xs) + z_ceiling\n",
    "    coorx_floor, coory_floor = xyz_2_coorxy(xs, ys, zs_floor, H, W)\n",
    "    coorx_ceil, coory_ceil = xyz_2_coorxy(xs, ys, zs_ceil, H, W)\n",
    "\n",
    "    floor_texture = np.stack([\n",
    "        map_coordinates(equirect_texture[..., 0], [coory_floor, coorx_floor], order=1, mode='wrap'),\n",
    "        map_coordinates(equirect_texture[..., 1], [coory_floor, coorx_floor], order=1, mode='wrap'),\n",
    "        map_coordinates(equirect_texture[..., 2], [coory_floor, coorx_floor], order=1, mode='wrap'),\n",
    "        np.zeros([t_h, t_w]) + alpha,\n",
    "    ], -1).reshape(-1, 4)\n",
    "    floor_xyz = np.stack([xs, ys, zs_floor], axis=-1).reshape(-1, 3)\n",
    "\n",
    "    ceil_texture = np.stack([\n",
    "        map_coordinates(equirect_texture[..., 0], [coory_ceil, coorx_ceil], order=1, mode='wrap'),\n",
    "        map_coordinates(equirect_texture[..., 1], [coory_ceil, coorx_ceil], order=1, mode='wrap'),\n",
    "        map_coordinates(equirect_texture[..., 2], [coory_ceil, coorx_ceil], order=1, mode='wrap'),\n",
    "        np.zeros([t_h, t_w]) + alpha,\n",
    "    ], -1).reshape(-1, 4)\n",
    "    ceil_xyz = np.stack([xs, ys, zs_ceil], axis=-1).reshape(-1, 3)\n",
    "\n",
    "    xy_poly = Polygon(xy)\n",
    "    with Pool(n_thread) as p:\n",
    "        sel = p.map(functools.partial(pt_in_poly, xy_poly), floor_xyz[:, :2])\n",
    "\n",
    "    return floor_texture[sel], floor_xyz[sel], ceil_texture[sel], ceil_xyz[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'assert/output_preprocess/demo_aligned_rgb.png'\n",
    "layout = 'assert/output/demo_aligned_rgb_cor_id.txt'\n",
    "camera_height = 1.6\n",
    "ppm = 120\n",
    "point_size = 0.0025\n",
    "alpha = 1.0\n",
    "threads = 10\n",
    "ignore_floor = False\n",
    "ignore_ceiling= False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading source (texture img, cor_id txt)\n",
    "equirect_texture = np.array(Image.open(img)) / 255.0\n",
    "with open(layout) as f:\n",
    "    cor_id = np.array([line.split() for line in f], np.float32)\n",
    "\n",
    "# Convert cor_id to 3d xyz\n",
    "N = len(cor_id) // 2\n",
    "H, W = equirect_texture.shape[:2]\n",
    "floor_z = -camera_height\n",
    "floor_xy = np_coor2xy(cor_id[1::2], floor_z, W, H)\n",
    "c = np.sqrt((floor_xy**2).sum(1))\n",
    "v = np_coory2v(cor_id[0::2, 1], H)\n",
    "ceil_z = (c * np.tan(v)).mean()\n",
    "\n",
    "# Warp each wall\n",
    "all_rgba, all_xyz = warp_walls(floor_xy, floor_z, ceil_z, H, W, ppm, alpha)\n",
    "\n",
    "# Warp floor and ceiling\n",
    "if not ignore_floor or not ignore_ceiling:\n",
    "    fi, fp, ci, cp = warp_floor_ceiling(floor_xy, floor_z, ceil_z, H, W,\n",
    "                                        ppm=ppm,\n",
    "                                        alpha=alpha,\n",
    "                                        n_thread=threads)\n",
    "\n",
    "    if not ignore_floor:\n",
    "        all_rgba.extend(fi)\n",
    "        all_xyz.extend(fp)\n",
    "\n",
    "    if not ignore_ceiling:\n",
    "        all_rgba.extend(ci)\n",
    "        all_xyz.extend(cp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of points:', len(all_rgba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_xyz = np.array(all_xyz)\n",
    "all_rgb = np.array(all_rgba)[:, :3]\n",
    "pcd = open3d.PointCloud()\n",
    "pcd.points = open3d.Vector3dVector(all_xyz)\n",
    "pcd.colors = open3d.Vector3dVector(all_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d import JVisualizer\n",
    "import open3d as o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = open3d.geometry.PointCloud()\n",
    "pcd.points = open3d.utility.Vector3dVector(all_xyz)\n",
    "pcd.colors = open3d.utility.Vector3dVector(all_rgb)\n",
    "visualizer = JVisualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3.PointCloud = o3.geometry.PointCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.add_geometry(pcd)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
